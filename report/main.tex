\documentclass{article}
\input{structure.tex}
\title{Scene Segmentation}
\author{Alex Konrad\\ \texttt{akonrad@uci.edu}}
\date{CS216 Final Project --- \today}
\begin{document}
\maketitle
\section*{Introduction}

Hi, Iâ€™m Alex Konrad and I chose to work on scene segmentation using
Conditional Random Fields, recreating a paper in Python code. I'll give
an overview of the paper and talk about my experience in implementation.

\section{Project Overview}

Scene Segmentation is the task of partitioning an image into regions
corresponding to the objects in them and assigning the correct class
labels to a given region.

For this project I mostly aimed to reproduce a paper by Verbeek and
Triggs from 2007 that applied Conditional Random Fields to the
scene segmentation problem.

\section{Data Sets}

Following Verbeeks and Triggs I applied the classifier
to the MSRC 9-class label object recognition dataset.

\section{Algorithms} 

A conditional random field is a structured prediction classifier that
can take context into account when making predictions by using a
graphical model to add dependencies between regions.

As you remember from class, conditional random fields are a distinct
type of Markov random field because they directly model the conditional
distribution, P(Y|X), rather than the joint distribution P(X,Y). 



\subsection{Features}

To build features, I decomposed the image into 16x16 patches to build
a feature vector. For each patch, I compute the 128-dimensional
SIFT descriptor vector (using OpenCV), a 36-dimensional color hue descriptor
vector, and a position vector indicating which patch it belongs in.

But the CRF classifier doesn't work directly with the image feature data.
For each of these features, I cluster the feature response from
every patch in the entire training set together, and the actual features
are indicator vectors which designate the centroid assignment for that patch.
This allows us to classify a patch based on other most similar patches.

\section{Results}

Provide clear documentation of your results.   When possible, show visualizations of intermediate processing steps.  If you tried several different variants of an algorithm show a side-by-side comparison of how they worked on some of your data. If possible, include both qualitative visualizations of results (e.g., example outputs of an object detector on some test images) as well as quantitative evaluations (e.g., accuracy numbers, precision-recall curves etc.)

\section{Assessment and Evaluation}

Provide a discussion on your evaluation and assessment of the results:   having completed the project do you think the task was difficult or easy for a computer algorithm to try to solve? what were the limitations of your approach? what were the successes? how might you build a better system if you had more time? what aspects of the data limited your results? what was the weakest link? And so forth. Be honest in your assessment of your results. Similarly if the results are amazing, you should explain why if possible. You will earn full points if you write a well-written comprehensive report, even if your results are not very good... conversely you will get a low score if you write a poor report, even if you have very nice results.


\begin{thebibliography}{widest entry}
 \bibitem{VT} Scene Segmentation with Conditional Random Fields Learned from Partially Labeled Images. Jakob Verbeek and Bill Triggs, 2007. http://ljk.imag.fr/membres/Bill.Triggs/pubs/Verbeek-nips07.pdf
 \bibitem{CRF} An Introduction to Conditional Random
Fields for Relational Learning. Charles Sutton and Andrew McCallum, 2012. https://people.cs.umass.edu/~mccallum/papers/crf-tutorial.pdf
\bibitem{SIFT} Distinctive Image Features
from Scale-Invariant Keypoints. David G. Lowe, 2004.  https://www.cs.ubc.ca/~lowe/papers/ijcv04.pdf
\end{thebibliography}


\section*{Appendix}

% File contents
\begin{file}[hello.py]
\begin{lstlisting}[language=Python]
#! /usr/bin/python

import sys
sys.stdout.write("Hello World!\n")
\end{lstlisting}
\end{file}

\end{document}
